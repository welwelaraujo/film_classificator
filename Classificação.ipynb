{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import re\n",
    "from nltk import probability\n",
    "import random\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificaremos quais palavras estão mais frequentes após alguns preprocessamentos com o nltk. Usaremos a frquencia das top 5 palavras de cada grupo como features, além da densidade gramatical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv(r\"data\\corpus.csv\", encoding= 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10 = corpus[corpus[\"faixa_etaria\"] ==\"10\"]\n",
    "df12 = corpus[corpus[\"faixa_etaria\"] ==\"12\"]\n",
    "df14 = corpus[corpus[\"faixa_etaria\"] ==\"14\"]\n",
    "df16 = corpus[corpus[\"faixa_etaria\"] ==\"16\"]\n",
    "df18 = corpus[corpus[\"faixa_etaria\"] ==\"18\"]\n",
    "dfL = corpus[corpus[\"faixa_etaria\"] ==\"livre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10 = df10.append(dfL)\n",
    "df10[\"faixa_etaria\"] = \"10\"\n",
    "df16 = df16.append(df18)\n",
    "df16[\"faixa_etaria\"] = \"16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfCorpus = df10.append(df12)\n",
    "dfCorpus = dfCorpus.append(df14)\n",
    "dfCorpus = dfCorpus.append(df16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCorpus = dfCorpus.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titulo</th>\n",
       "      <th>faixa_etaria</th>\n",
       "      <th>sinopse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Querido Menino</td>\n",
       "      <td>14</td>\n",
       "      <td>David Sheff (Steve Carell) é um conceituado jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Correndo Atrás de um Pai</td>\n",
       "      <td>14</td>\n",
       "      <td>Quando descobrem que a mãe (Glenn Close) sempr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O Que Te Faz Mais Forte</td>\n",
       "      <td>14</td>\n",
       "      <td>As memórias de Jeff Bauman (Jake Gyllenhaal) s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Odisseia</td>\n",
       "      <td>10</td>\n",
       "      <td>O aventureiro oceânico e cineasta francês Jacq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Limites</td>\n",
       "      <td>16</td>\n",
       "      <td>Laura (Vera Farmiga) é uma mulher que busca vi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     titulo faixa_etaria  \\\n",
       "0            Querido Menino           14   \n",
       "1  Correndo Atrás de um Pai           14   \n",
       "2   O Que Te Faz Mais Forte           14   \n",
       "3                A Odisseia           10   \n",
       "4                   Limites           16   \n",
       "\n",
       "                                             sinopse  \n",
       "0  David Sheff (Steve Carell) é um conceituado jo...  \n",
       "1  Quando descobrem que a mãe (Glenn Close) sempr...  \n",
       "2  As memórias de Jeff Bauman (Jake Gyllenhaal) s...  \n",
       "3  O aventureiro oceânico e cineasta francês Jacq...  \n",
       "4  Laura (Vera Farmiga) é uma mulher que busca vi...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCorpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusTrain = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluindo targets vazios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCorpus[\"faixa_etaria\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando o corpus por target para realizar as análises de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus10 = dfCorpus[dfCorpus[\"faixa_etaria\"] ==\"10\"]\n",
    "corpus12 = dfCorpus[dfCorpus[\"faixa_etaria\"] ==\"12\"]\n",
    "corpus14 = dfCorpus[dfCorpus[\"faixa_etaria\"] ==\"14\"]\n",
    "corpus16 = dfCorpus[dfCorpus[\"faixa_etaria\"] ==\"16\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando stopwords com auxilio da  biblioteca nltk e stopwords públicos disponiveis em português no Github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.read_csv(\"data\\stopwords.txt\",header = None)\n",
    "b = b[0].tolist()\n",
    "b = [ b[i][:-1].strip() for i in range(0,len(b)) ]\n",
    "stop_words = set(stopwords.words('portuguese') + list(punctuation) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chamando função que utiliza a Função FreqDist do NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Freq10,df10 = get_freq(corpus10)\n",
    "Freq12,df12 = get_freq(corpus12)\n",
    "Freq14,df14 = get_freq(corpus14)\n",
    "Freq16,df16 = get_freq(corpus16)\n",
    "# Freq18,df18 = get_freq(corpus18)\n",
    "# FreqL,dfL = get_freq(corpusL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando as 5 principais palavras de cada classe observamos que o radical \"vid\" aparece em todas as categorias, sendo assim, ele foi tirado de todo o corpus por não apresentar relevancia estatistica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common10 = commom(Freq10)\n",
    "common12 = commom(Freq12)\n",
    "common14 = commom(Freq14)\n",
    "common16 = commom(Freq16)\n",
    "# common18 = commom(Freq18)\n",
    "# commonL = commom(FreqL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando a densidade lexical de cada resenha e armazenado isso em uma variavel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGram = [(len(dfCorpus.iloc[i]['sinopse'])/len(set(dfCorpus.iloc[0]['sinopse']))) for i in range(0,len(dfCorpus))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusTrain = corpusTrain.append(dfGram)\n",
    "corpusTrain.columns = [\"densidade_gramatical\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGram_title = [(len(dfCorpus.iloc[i]['titulo'])/len(set(dfCorpus.iloc[0]['titulo']))) for i in range(0,len(dfCorpus))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusTrain[\"densidade_gramatical_t\"] = dfGram_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_freq = []\n",
    "for filme in range(0,len(dfCorpus)):\n",
    "    sinopse = dfCorpus.iloc[filme]['sinopse']\n",
    "    s = generate_label(sinopse,common10,common12,common14,common16)\n",
    "    score_freq.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusTrain[\"score\"] = score_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusTrain[\"target\"] = dfCorpus[\"faixa_etaria\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusTrain = corpusTrain[corpusTrain[\"target\"] !=\"vazio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusTrain = corpusTrain.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(corpusTrain[['densidade_gramatical',\"score\",'densidade_gramatical_t']], corpusTrain[\"target\"], test_size=0.2,random_state=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commom(freq):\n",
    "    freq = freq.most_common(5)\n",
    "    freq = [freq[i][0] for i in range(0,len(freq))]\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq(corp):\n",
    "    df = corp[\"sinopse\"].tolist()\n",
    "    df = \"\".join(df)\n",
    "    df = re.findall(r\"[\\w']+\", df)\n",
    "    df = [ df[i].lower() for i in range(0,len(df)) ]\n",
    "    df = [word for word in df if word not in stop_words]\n",
    "    st = nltk.stem.RSLPStemmer()\n",
    "    df = [ st.stem(df[i]) for i in range(0,len(df)) ]\n",
    "    df = [x for x in df if x != \"vid\"]\n",
    "    return probability.FreqDist(df), df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_label(sinopse,c10,c12,c14,c16):\n",
    "\n",
    "    a = sinopse\n",
    "    a = \"\".join(a)\n",
    "    a = re.findall(r\"[\\w']+\", a)\n",
    "    a = [ a[i].lower() for i in range(0,len(a)) ]\n",
    "    a = [word for word in a if word not in stop_words]\n",
    "    st = nltk.stem.RSLPStemmer()\n",
    "    a = [ st.stem(a[i]) for i in range(0,len(a)) ]\n",
    "    a = [x for x in a if x != \"vid\"]\n",
    "    \n",
    "    select = 0\n",
    "    \n",
    "    for element in a:\n",
    "        if element in c10:\n",
    "            select+=1\n",
    "        else:\n",
    "            pass\n",
    "        if element in c12:\n",
    "            select+=1\n",
    "        else:\n",
    "            pass\n",
    "        if element in c14:\n",
    "            select+=1\n",
    "        else:\n",
    "            pass\n",
    "        if element in c16:\n",
    "            select+=1\n",
    "        else:\n",
    "            pass\n",
    "    return select"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
